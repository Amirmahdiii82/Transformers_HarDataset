{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "qL0K8Z91OMxx",
        "ubp9lSqgJUx7",
        "ELwgzDfGFXvr",
        "fQFlVvECeZsD",
        "Ggb4EOeBuSYQ",
        "OsNaqujTeiGx",
        "aBJu19_uvqWW",
        "-NBcJXJkfgUI",
        "rEGXsvVira03",
        "DY5JMY1Yftsr",
        "mbpEEA0g1-Be",
        "B_LljZFVAFPA",
        "9csGqnCvtFAS",
        "lpJ3wtyctQJH",
        "BrHQCv7q7LF_",
        "BLT4w0ZfAhlJ",
        "uC2GhaXfA8vC",
        "oBW2SLfEEkCp",
        "oK20iNRI3Xxb"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Google Drive**"
      ],
      "metadata": {
        "id": "qL0K8Z91OMxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vJruzJ6Yr4qZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GPU**"
      ],
      "metadata": {
        "id": "ubp9lSqgJUx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "FvB2dRFFJZqK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52ce05b6-ef99-4a95-a454-f5078f60c693"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Aug  8 20:36:42 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   63C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Install**"
      ],
      "metadata": {
        "id": "ELwgzDfGFXvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "id": "dQ9OIgAs4iWa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b7f66fc-e2f7-480e-aaa5-7f3f5d61f614"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in c:\\users\\pc\\anaconda3\\envs\\howsam-deep\\lib\\site-packages (0.9.3)\n",
            "Requirement already satisfied: torch>=1.3.1 in c:\\users\\pc\\anaconda3\\envs\\howsam-deep\\lib\\site-packages (from torchmetrics) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in c:\\users\\pc\\anaconda3\\envs\\howsam-deep\\lib\\site-packages (from torchmetrics) (1.22.3)\n",
            "Requirement already satisfied: packaging in c:\\users\\pc\\anaconda3\\envs\\howsam-deep\\lib\\site-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: typing_extensions in c:\\users\\pc\\anaconda3\\envs\\howsam-deep\\lib\\site-packages (from torch>=1.3.1->torchmetrics) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\pc\\anaconda3\\envs\\howsam-deep\\lib\\site-packages (from packaging->torchmetrics) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "fQFlVvECeZsD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jnc2LOc9eRjD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms as T\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from torchmetrics import Accuracy\n",
        "from tqdm import tqdm\n",
        "\n",
        "import glob\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Init**"
      ],
      "metadata": {
        "id": "Ggb4EOeBuSYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_cls = 6"
      ],
      "metadata": {
        "id": "K07nHNbTuUzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "OsNaqujTeiGx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load dataset"
      ],
      "metadata": {
        "id": "MHXCDiv6vVv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.listdir('/content/drive/MyDrive/UCI HAR Dataset/train/Inertial Signals')"
      ],
      "metadata": {
        "id": "UcwR1dCR-gWB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d8d0a75-f349-4002-8233-0face22d3339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['body_acc_x_train.txt',\n",
              " 'body_acc_y_train.txt',\n",
              " 'body_acc_z_train.txt',\n",
              " 'body_gyro_x_train.txt',\n",
              " 'body_gyro_y_train.txt',\n",
              " 'body_gyro_z_train.txt',\n",
              " 'total_acc_x_train.txt',\n",
              " 'total_acc_y_train.txt',\n",
              " 'total_acc_z_train.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def har_dataset(phase):\n",
        "  x = []\n",
        "  data_dir = f'/content/drive/MyDrive/UCI HAR Dataset/{phase}/Inertial Signals/*'\n",
        "  for file_dir in glob.glob(data_dir):\n",
        "    x.append(np.loadtxt(file_dir))\n",
        "  y = np.loadtxt(f'/content/drive/MyDrive/UCI HAR Dataset/{phase}/y_{phase}.txt')\n",
        "  #\n",
        "  x = torch.FloatTensor(x).permute(1, 2, 0)\n",
        "  y = torch.LongTensor(y) - 1\n",
        "  return x, y"
      ],
      "metadata": {
        "id": "h5BiuwkInC4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = har_dataset('train')\n",
        "x_test, y_test = har_dataset('test')"
      ],
      "metadata": {
        "id": "rgh2qOJLnsy5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82e6896e-2de3-402f-fb86-b45688d12fac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_9220\\2846403758.py:8: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:204.)\n",
            "  x = torch.FloatTensor(x).permute(1, 2, 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape, y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4rzI_aBZc1n",
        "outputId": "69bb7c1c-c17b-4463-c4aa-2fb658a7c73b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([7352, 128, 9]), torch.Size([7352]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ST1j1DIwpUkr",
        "outputId": "31dc190f-81ae-4374-b663-493a0a0e6b6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2947, 128, 9]), torch.Size([2947]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekH_2S4Eo_Bm",
        "outputId": "85daaa60-1aab-4006-9102-8c3e3b33d4de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4, 4, 4,  ..., 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.unique(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASX5bAP-14Cv",
        "outputId": "b2ac0378-221b-4c67-9e59-b57d741035d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TensorDataset"
      ],
      "metadata": {
        "id": "FpY1h4DZvHmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = TensorDataset(x_train, y_train)\n",
        "test_set = TensorDataset(x_test, y_test)"
      ],
      "metadata": {
        "id": "q-1IcLDEqtzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoader"
      ],
      "metadata": {
        "id": "3aQRTc6n7-hi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_set, batch_size=256, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size=256, shuffle=False)"
      ],
      "metadata": {
        "id": "MWf29MbO79gp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = next(iter(train_loader))\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBAeQLxJusuD",
        "outputId": "dc3934fe-b171-47fe-9e30-791b47b3e00d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 128, 9])\n",
            "torch.Size([256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visulaize"
      ],
      "metadata": {
        "id": "aBJu19_uvqWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(x[5])"
      ],
      "metadata": {
        "id": "fg2QaG5EvbRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "-NBcJXJkfgUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Transformer(9, 3, 3, 3, 36, 0.2, 'gelu', device='cuda')\n",
        "model"
      ],
      "metadata": {
        "id": "FkZo3wSRyFod",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42571f28-5a0a-45e0-d5ae-797802bac779"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (encoder): TransformerEncoder(\n",
              "    (layers): ModuleList(\n",
              "      (0): TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=9, out_features=9, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=9, out_features=36, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "        (linear2): Linear(in_features=36, out_features=9, bias=True)\n",
              "        (norm1): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.2, inplace=False)\n",
              "        (dropout2): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (1): TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=9, out_features=9, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=9, out_features=36, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "        (linear2): Linear(in_features=36, out_features=9, bias=True)\n",
              "        (norm1): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.2, inplace=False)\n",
              "        (dropout2): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (2): TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=9, out_features=9, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=9, out_features=36, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "        (linear2): Linear(in_features=36, out_features=9, bias=True)\n",
              "        (norm1): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.2, inplace=False)\n",
              "        (dropout2): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (norm): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (decoder): TransformerDecoder(\n",
              "    (layers): ModuleList(\n",
              "      (0): TransformerDecoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=9, out_features=9, bias=True)\n",
              "        )\n",
              "        (multihead_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=9, out_features=9, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=9, out_features=36, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "        (linear2): Linear(in_features=36, out_features=9, bias=True)\n",
              "        (norm1): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm3): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.2, inplace=False)\n",
              "        (dropout2): Dropout(p=0.2, inplace=False)\n",
              "        (dropout3): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (1): TransformerDecoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=9, out_features=9, bias=True)\n",
              "        )\n",
              "        (multihead_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=9, out_features=9, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=9, out_features=36, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "        (linear2): Linear(in_features=36, out_features=9, bias=True)\n",
              "        (norm1): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm3): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.2, inplace=False)\n",
              "        (dropout2): Dropout(p=0.2, inplace=False)\n",
              "        (dropout3): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (2): TransformerDecoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=9, out_features=9, bias=True)\n",
              "        )\n",
              "        (multihead_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=9, out_features=9, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=9, out_features=36, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "        (linear2): Linear(in_features=36, out_features=9, bias=True)\n",
              "        (norm1): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm3): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.2, inplace=False)\n",
              "        (dropout2): Dropout(p=0.2, inplace=False)\n",
              "        (dropout3): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (norm): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.decoder.layers[2].linear1.bias.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ozo9MM1Ll3Gg",
        "outputId": "5dbe7f37-10c6-40e8-9091-72cef50c6260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([36])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Transformer(9, 3, 8, 0).encoder\n",
        "model"
      ],
      "metadata": {
        "id": "FelN8-i1nu9z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24674916-ec44-4bea-fa5a-49ca59864528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TransformerEncoder(\n",
              "  (layers): ModuleList(\n",
              "    (0): TransformerEncoderLayer(\n",
              "      (self_attn): MultiheadAttention(\n",
              "        (out_proj): NonDynamicallyQuantizableLinear(in_features=9, out_features=9, bias=True)\n",
              "      )\n",
              "      (linear1): Linear(in_features=9, out_features=2048, bias=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (linear2): Linear(in_features=2048, out_features=9, bias=True)\n",
              "      (norm1): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout1): Dropout(p=0.1, inplace=False)\n",
              "      (dropout2): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerEncoderLayer(\n",
              "      (self_attn): MultiheadAttention(\n",
              "        (out_proj): NonDynamicallyQuantizableLinear(in_features=9, out_features=9, bias=True)\n",
              "      )\n",
              "      (linear1): Linear(in_features=9, out_features=2048, bias=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (linear2): Linear(in_features=2048, out_features=9, bias=True)\n",
              "      (norm1): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout1): Dropout(p=0.1, inplace=False)\n",
              "      (dropout2): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerEncoderLayer(\n",
              "      (self_attn): MultiheadAttention(\n",
              "        (out_proj): NonDynamicallyQuantizableLinear(in_features=9, out_features=9, bias=True)\n",
              "      )\n",
              "      (linear1): Linear(in_features=9, out_features=2048, bias=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (linear2): Linear(in_features=2048, out_features=9, bias=True)\n",
              "      (norm1): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout1): Dropout(p=0.1, inplace=False)\n",
              "      (dropout2): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerEncoderLayer(\n",
              "      (self_attn): MultiheadAttention(\n",
              "        (out_proj): NonDynamicallyQuantizableLinear(in_features=9, out_features=9, bias=True)\n",
              "      )\n",
              "      (linear1): Linear(in_features=9, out_features=2048, bias=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (linear2): Linear(in_features=2048, out_features=9, bias=True)\n",
              "      (norm1): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout1): Dropout(p=0.1, inplace=False)\n",
              "      (dropout2): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerEncoderLayer(\n",
              "      (self_attn): MultiheadAttention(\n",
              "        (out_proj): NonDynamicallyQuantizableLinear(in_features=9, out_features=9, bias=True)\n",
              "      )\n",
              "      (linear1): Linear(in_features=9, out_features=2048, bias=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (linear2): Linear(in_features=2048, out_features=9, bias=True)\n",
              "      (norm1): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout1): Dropout(p=0.1, inplace=False)\n",
              "      (dropout2): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerEncoderLayer(\n",
              "      (self_attn): MultiheadAttention(\n",
              "        (out_proj): NonDynamicallyQuantizableLinear(in_features=9, out_features=9, bias=True)\n",
              "      )\n",
              "      (linear1): Linear(in_features=9, out_features=2048, bias=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (linear2): Linear(in_features=2048, out_features=9, bias=True)\n",
              "      (norm1): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout1): Dropout(p=0.1, inplace=False)\n",
              "      (dropout2): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerEncoderLayer(\n",
              "      (self_attn): MultiheadAttention(\n",
              "        (out_proj): NonDynamicallyQuantizableLinear(in_features=9, out_features=9, bias=True)\n",
              "      )\n",
              "      (linear1): Linear(in_features=9, out_features=2048, bias=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (linear2): Linear(in_features=2048, out_features=9, bias=True)\n",
              "      (norm1): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout1): Dropout(p=0.1, inplace=False)\n",
              "      (dropout2): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerEncoderLayer(\n",
              "      (self_attn): MultiheadAttention(\n",
              "        (out_proj): NonDynamicallyQuantizableLinear(in_features=9, out_features=9, bias=True)\n",
              "      )\n",
              "      (linear1): Linear(in_features=9, out_features=2048, bias=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (linear2): Linear(in_features=2048, out_features=9, bias=True)\n",
              "      (norm1): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout1): Dropout(p=0.1, inplace=False)\n",
              "      (dropout2): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (norm): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_layer = nn.TransformerEncoderLayer(9, 3, 36, device='cuda')"
      ],
      "metadata": {
        "id": "u4gtnKfpoPI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.TransformerEncoder(encoder_layer, 8)\n",
        "model"
      ],
      "metadata": {
        "id": "e3lkHWacoJih",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d779d5c8-cc6d-4165-9e04-ffe0650ba990"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TransformerEncoder(\n",
              "  (layers): ModuleList(\n",
              "    (0): TransformerEncoderLayer(\n",
              "      (self_attn): MultiheadAttention(\n",
              "        (out_proj): NonDynamicallyQuantizableLinear(in_features=9, out_features=9, bias=True)\n",
              "      )\n",
              "      (linear1): Linear(in_features=9, out_features=36, bias=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (linear2): Linear(in_features=36, out_features=9, bias=True)\n",
              "      (norm1): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout1): Dropout(p=0.1, inplace=False)\n",
              "      (dropout2): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerEncoderLayer(\n",
              "      (self_attn): MultiheadAttention(\n",
              "        (out_proj): NonDynamicallyQuantizableLinear(in_features=9, out_features=9, bias=True)\n",
              "      )\n",
              "      (linear1): Linear(in_features=9, out_features=36, bias=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (linear2): Linear(in_features=36, out_features=9, bias=True)\n",
              "      (norm1): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout1): Dropout(p=0.1, inplace=False)\n",
              "      (dropout2): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerEncoderLayer(\n",
              "      (self_attn): MultiheadAttention(\n",
              "        (out_proj): NonDynamicallyQuantizableLinear(in_features=9, out_features=9, bias=True)\n",
              "      )\n",
              "      (linear1): Linear(in_features=9, out_features=36, bias=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (linear2): Linear(in_features=36, out_features=9, bias=True)\n",
              "      (norm1): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout1): Dropout(p=0.1, inplace=False)\n",
              "      (dropout2): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerEncoderLayer(\n",
              "      (self_attn): MultiheadAttention(\n",
              "        (out_proj): NonDynamicallyQuantizableLinear(in_features=9, out_features=9, bias=True)\n",
              "      )\n",
              "      (linear1): Linear(in_features=9, out_features=36, bias=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (linear2): Linear(in_features=36, out_features=9, bias=True)\n",
              "      (norm1): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout1): Dropout(p=0.1, inplace=False)\n",
              "      (dropout2): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerEncoderLayer(\n",
              "      (self_attn): MultiheadAttention(\n",
              "        (out_proj): NonDynamicallyQuantizableLinear(in_features=9, out_features=9, bias=True)\n",
              "      )\n",
              "      (linear1): Linear(in_features=9, out_features=36, bias=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (linear2): Linear(in_features=36, out_features=9, bias=True)\n",
              "      (norm1): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout1): Dropout(p=0.1, inplace=False)\n",
              "      (dropout2): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerEncoderLayer(\n",
              "      (self_attn): MultiheadAttention(\n",
              "        (out_proj): NonDynamicallyQuantizableLinear(in_features=9, out_features=9, bias=True)\n",
              "      )\n",
              "      (linear1): Linear(in_features=9, out_features=36, bias=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (linear2): Linear(in_features=36, out_features=9, bias=True)\n",
              "      (norm1): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout1): Dropout(p=0.1, inplace=False)\n",
              "      (dropout2): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerEncoderLayer(\n",
              "      (self_attn): MultiheadAttention(\n",
              "        (out_proj): NonDynamicallyQuantizableLinear(in_features=9, out_features=9, bias=True)\n",
              "      )\n",
              "      (linear1): Linear(in_features=9, out_features=36, bias=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (linear2): Linear(in_features=36, out_features=9, bias=True)\n",
              "      (norm1): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout1): Dropout(p=0.1, inplace=False)\n",
              "      (dropout2): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerEncoderLayer(\n",
              "      (self_attn): MultiheadAttention(\n",
              "        (out_proj): NonDynamicallyQuantizableLinear(in_features=9, out_features=9, bias=True)\n",
              "      )\n",
              "      (linear1): Linear(in_features=9, out_features=36, bias=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (linear2): Linear(in_features=36, out_features=9, bias=True)\n",
              "      (norm1): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((9,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout1): Dropout(p=0.1, inplace=False)\n",
              "      (dropout2): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers[0].linear1.weight"
      ],
      "metadata": {
        "id": "nWk0vYkZpODM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8457afe-a9b4-48bc-ca78-79976b64131c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 1.6543e-01, -1.1922e-01, -2.2748e-01,  2.5058e-01,  6.2822e-02,\n",
              "         -2.4685e-01,  1.5218e-01,  1.6949e-02, -2.1442e-01],\n",
              "        [ 6.3605e-03, -3.6823e-02, -2.6280e-01, -1.1649e-01,  1.4373e-02,\n",
              "          1.7927e-01,  1.6837e-01,  2.4524e-01, -5.9314e-02],\n",
              "        [-2.0802e-01,  2.8351e-01,  3.2805e-01, -2.4618e-01, -2.0542e-01,\n",
              "          2.1346e-01,  3.2289e-01, -2.7927e-01,  2.6689e-01],\n",
              "        [-1.0862e-01,  2.1609e-01,  2.7781e-01,  2.2568e-01,  1.0942e-01,\n",
              "          1.2449e-01, -5.8544e-02,  1.5690e-01, -2.0948e-01],\n",
              "        [-2.2359e-01,  6.4879e-02, -2.4895e-01,  2.9622e-01, -1.4340e-02,\n",
              "          2.6352e-01,  9.4844e-02,  9.5034e-02, -6.5691e-02],\n",
              "        [-2.5453e-01,  2.0097e-01, -3.0952e-01, -2.9513e-01, -1.4800e-01,\n",
              "          1.1973e-01,  2.5859e-01,  2.9979e-01, -1.7350e-01],\n",
              "        [ 1.1718e-01, -1.9370e-01,  3.1758e-01,  2.8229e-01, -3.0494e-01,\n",
              "         -7.6658e-02,  3.0346e-01, -3.6678e-02,  2.9741e-01],\n",
              "        [ 3.3403e-02, -4.0076e-02, -2.1782e-01, -2.2718e-01,  5.4924e-02,\n",
              "         -4.5140e-02,  1.3653e-01,  7.5092e-02, -2.0317e-01],\n",
              "        [-1.2887e-03,  2.2496e-01, -1.9561e-01, -3.0510e-01,  9.4531e-02,\n",
              "         -2.8827e-01, -2.8900e-01,  9.7754e-03,  3.0102e-01],\n",
              "        [ 1.8233e-01,  5.1895e-02,  1.9642e-02,  1.1892e-01,  1.1185e-01,\n",
              "         -1.3879e-01, -3.0183e-01,  2.2812e-01, -5.0106e-02],\n",
              "        [ 2.2274e-01, -4.8785e-02,  8.2017e-02, -2.2546e-01,  1.7265e-01,\n",
              "          2.8402e-01, -2.7864e-01, -1.0557e-01, -2.1158e-01],\n",
              "        [-3.3005e-01, -1.4291e-01,  1.7617e-01, -1.3888e-01,  2.7254e-01,\n",
              "          2.5468e-01,  2.5263e-01,  2.3840e-01, -1.7841e-01],\n",
              "        [ 1.6946e-01, -3.7612e-02,  2.7616e-01,  9.3193e-02, -7.3951e-03,\n",
              "          3.0291e-01,  1.7016e-01, -2.9960e-01,  2.4033e-04],\n",
              "        [-3.7226e-02, -2.8532e-01,  2.9050e-01,  1.4624e-01,  6.2673e-02,\n",
              "          1.2701e-01,  3.0368e-01,  2.8072e-01,  1.9423e-01],\n",
              "        [-2.4202e-01,  2.9973e-01, -3.6260e-02,  2.3041e-01, -2.8804e-01,\n",
              "         -7.3892e-03, -2.0365e-01,  1.1212e-01, -3.1233e-01],\n",
              "        [-1.9507e-01,  2.1020e-01,  1.7110e-01,  2.3800e-01, -2.4012e-01,\n",
              "         -1.4773e-01, -1.5121e-01,  1.0006e-01,  1.4588e-01],\n",
              "        [-2.6395e-01,  1.3037e-01,  2.5638e-01,  2.1477e-01, -2.6091e-01,\n",
              "          1.0115e-01, -4.2906e-02,  2.0784e-01, -1.6737e-01],\n",
              "        [-1.8862e-01, -2.9897e-02,  1.8269e-02, -1.9120e-01,  1.1906e-01,\n",
              "         -9.2135e-02, -1.8338e-01,  2.7664e-01,  2.4008e-01],\n",
              "        [ 2.8242e-01, -8.3491e-02,  8.0951e-02,  2.4366e-01,  2.8599e-01,\n",
              "         -6.0301e-02, -1.1929e-01, -9.8397e-02,  2.1239e-01],\n",
              "        [-1.8263e-01, -9.4047e-02, -1.1238e-01,  9.2025e-02, -1.7194e-01,\n",
              "          2.3176e-01,  2.4223e-01,  2.2947e-01, -2.1115e-02],\n",
              "        [-2.3998e-01,  2.8309e-01, -1.8272e-01, -1.5009e-01,  2.6731e-01,\n",
              "         -1.6961e-02,  1.5240e-01, -2.1952e-02, -1.4638e-01],\n",
              "        [ 2.1571e-01,  7.8651e-02, -8.8811e-02,  1.8354e-01,  3.2332e-01,\n",
              "         -4.2308e-02,  2.1353e-01, -1.5936e-01,  1.8963e-02],\n",
              "        [-3.3270e-01,  1.4407e-01,  8.1628e-02, -6.2504e-02,  1.6763e-02,\n",
              "          2.7311e-01,  2.3885e-01, -2.6471e-01, -2.8793e-01],\n",
              "        [-1.3277e-01, -1.6829e-02, -1.8509e-01,  2.3392e-01, -3.1548e-02,\n",
              "          2.6406e-01,  1.7592e-01, -4.0587e-02, -2.8520e-01],\n",
              "        [ 3.2298e-01, -2.1309e-01,  8.4829e-02, -2.8636e-01, -1.5494e-01,\n",
              "         -1.2514e-01, -3.2350e-01,  1.4933e-02, -2.2368e-01],\n",
              "        [ 4.7784e-02, -1.8346e-01, -2.9990e-01, -7.1329e-02,  7.9124e-02,\n",
              "          2.1256e-01, -1.1722e-01, -2.8147e-01, -2.1104e-01],\n",
              "        [-2.1295e-01,  1.1113e-01,  1.7790e-01,  8.6267e-03, -4.4477e-03,\n",
              "          1.4543e-01, -2.7054e-01, -2.7164e-01,  3.1623e-01],\n",
              "        [ 2.6730e-01, -2.0365e-01,  1.9748e-01,  3.0604e-01,  7.0196e-03,\n",
              "          3.1234e-01, -1.1966e-01, -1.3304e-01, -2.1372e-01],\n",
              "        [ 1.8774e-01, -3.2484e-01,  3.3556e-02,  1.5674e-01,  2.8963e-01,\n",
              "          8.8120e-02, -1.8029e-01, -1.6198e-01, -7.6750e-02],\n",
              "        [-9.9552e-02,  2.6898e-01,  1.7924e-01, -8.5333e-02, -3.5033e-02,\n",
              "         -1.0232e-02,  2.8748e-01,  1.9562e-01,  1.9637e-01],\n",
              "        [ 2.2478e-01, -1.0084e-01,  3.0071e-01, -2.3937e-01, -2.4676e-01,\n",
              "         -6.7308e-02,  7.0321e-02,  2.1506e-01,  3.0279e-01],\n",
              "        [ 7.2690e-02, -4.0747e-02, -2.8273e-01, -6.6908e-02,  2.6552e-01,\n",
              "         -5.8209e-02,  9.6979e-02, -6.2542e-02, -1.8861e-01],\n",
              "        [ 4.3843e-02,  3.7270e-02, -1.6787e-01, -1.3061e-01, -2.3679e-01,\n",
              "         -3.2885e-01, -1.8262e-01, -1.6282e-01, -2.0980e-01],\n",
              "        [-1.0901e-01, -2.6665e-01, -3.1562e-01, -7.7817e-02,  3.2108e-01,\n",
              "          3.3328e-01,  8.4834e-02, -2.3093e-01, -1.9445e-01],\n",
              "        [-1.5128e-01, -2.3783e-01,  2.6204e-01, -1.1563e-01, -2.6421e-01,\n",
              "          1.9409e-01,  1.9087e-01,  2.4791e-02,  4.9825e-02],\n",
              "        [-2.1457e-01, -2.7439e-01, -1.8470e-01, -2.4114e-01,  7.8729e-02,\n",
              "         -3.6639e-02,  1.1247e-01,  2.9581e-02, -2.0837e-01]], device='cuda:0',\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nn.MultiheadAttention()"
      ],
      "metadata": {
        "id": "Zof3vdF_pinh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HAR Model"
      ],
      "metadata": {
        "id": "rEGXsvVira03"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerModel(nn.Module):\n",
        "\n",
        "  def __init__(self, d_model, nhead, num_enc, d_feed, dropout, activation):\n",
        "    super().__init__()\n",
        "    self.encoder = nn.Transformer(d_model,\n",
        "                                  nhead,\n",
        "                                  num_enc,\n",
        "                                  0,\n",
        "                                  d_feed,\n",
        "                                  dropout,\n",
        "                                  activation,\n",
        "                                  batch_first=True).encoder\n",
        "    # cls\n",
        "    self.fc = nn.LazyLinear(num_cls)\n",
        "    # input layer\n",
        "    self.linear0 = nn.LazyLinear(d_model)\n",
        "    self.bn0 = nn.LazyBatchNorm1d()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.bn0(self.linear0(x)).relu()\n",
        "    y = self.encoder(x)\n",
        "    # y = y.mean(dim=1)\n",
        "    y = self.fc(y[:, -1])\n",
        "    # y = y.mean(dim=1)\n",
        "    return y"
      ],
      "metadata": {
        "id": "cVjvx5-OrZb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TransformerModel(128, 8, 8, 256, 0.1, 'relu')\n",
        "# model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5v5VYUosteZm",
        "outputId": "d2bfe14a-fe7a-426c-ac89-0f36d68a4925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "C:\\Users\\PC\\anaconda3\\envs\\howsam-deep\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(x).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGDI8b7otvUl",
        "outputId": "7682b15d-6219-4eb6-b568-502256765685"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Params"
      ],
      "metadata": {
        "id": "IHsQ623pOs3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def num_params(model, k=1e6):\n",
        "  nums = sum(p.numel() for p in model.parameters())/k\n",
        "  return nums"
      ],
      "metadata": {
        "id": "K_JNWs7q0m1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_params(model, 1e6)"
      ],
      "metadata": {
        "id": "VaBa7Ao90-66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d5aa646-6008-4105-d57a-85d5b6212719"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.062406"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Device"
      ],
      "metadata": {
        "id": "DY5JMY1Yftsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "id": "Ce6_MpTcfrGi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a663d28-d870-496d-e949-d83c5ac653ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "mbpEEA0g1-Be"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "metadata": {
        "id": "G6s889_UrqDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Functions"
      ],
      "metadata": {
        "id": "B_LljZFVAFPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, train_loader, loss_fn, optimizer, epoch=None):\n",
        "  model.train()\n",
        "  loss_train = AverageMeter()\n",
        "  acc_train = Accuracy().to(device)\n",
        "  with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
        "    for inputs, targets in tepoch:\n",
        "      if epoch is not None:\n",
        "        tepoch.set_description(f\"Epoch {epoch}\")\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      loss.backward()\n",
        "      nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      loss_train.update(loss.item())\n",
        "      acc_train(outputs, targets.int())\n",
        "      tepoch.set_postfix(loss=loss_train.avg,\n",
        "                         accuracy=100.*acc_train.compute().item())\n",
        "  return model, loss_train.avg, acc_train.compute().item()"
      ],
      "metadata": {
        "id": "4W9MVeEqAYiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validation(model, test_loader, loss_fn):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    loss_valid = AverageMeter()\n",
        "    acc_valid = Accuracy().to(device)\n",
        "    for i, (inputs, targets) in enumerate(test_loader):\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "\n",
        "      outputs = model(inputs)\n",
        "      loss = loss_fn(outputs, targets)\n",
        "\n",
        "      loss_valid.update(loss.item())\n",
        "      acc_valid(outputs, targets.int())\n",
        "  return loss_valid.avg, acc_valid.compute().item()"
      ],
      "metadata": {
        "id": "ZEoGrXwZAaym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Efficient way for set hyperparams"
      ],
      "metadata": {
        "id": "9csGqnCvtFAS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: check forward path\n",
        "\n",
        "Calculate loss for one batch"
      ],
      "metadata": {
        "id": "lpJ3wtyctQJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = TransformerModel(128, 8, 8, 256, 0.1, 'relu').to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "x_batch, y_batch = next(iter(train_loader))\n",
        "outputs = model(x_batch.to(device))\n",
        "loss = loss_fn(outputs, y_batch.to(device))\n",
        "print(loss)"
      ],
      "metadata": {
        "id": "QnE4F4GkzzaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: check backward path\n",
        "\n",
        "Select 5 random batches and train the model"
      ],
      "metadata": {
        "id": "BrHQCv7q7LF_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_, mini_train_dataset = random_split(train_set, (len(train_set)-500, 500))\n",
        "mini_train_loader = DataLoader(mini_train_dataset, 20)"
      ],
      "metadata": {
        "id": "Jxz5DXoj61mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TransformerModel(128, 8, 8, 256, 0.1, 'relu').to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "J8yz1meO_fUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ],
      "metadata": {
        "id": "g0AG7IWGEcdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "  model, _, _ = train_one_epoch(model, mini_train_loader, loss_fn, optimizer, epoch)"
      ],
      "metadata": {
        "id": "PK-P20hI3snf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: select best lr\n",
        "\n",
        "Train all data for one epoch"
      ],
      "metadata": {
        "id": "BLT4w0ZfAhlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "for lr in [0.9, 0.5, 0.2, 0.1, 0.01, 0.001, 0.0001]:\n",
        "  print(f'LR={lr}')\n",
        "  model = TransformerModel(128, 8, 256, 0.1, 8, 6).to(device)\n",
        "  # model = torch.load('model.pt')\n",
        "  optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=1e-4, momentum=0.9)\n",
        "  for epoch in range(num_epochs):\n",
        "    model, _, _ = train_one_epoch(model, train_loader, loss_fn, optimizer, epoch)\n",
        "  print()"
      ],
      "metadata": {
        "id": "c7tlXlY4_Dwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: small grid (optional)\n",
        "\n",
        "Create a small grid based on the WD and the best LR\n",
        "\n"
      ],
      "metadata": {
        "id": "uC2GhaXfA8vC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "\n",
        "for lr in [0.05, 0.04, 0.03, 0.02, 0.01, 0.009, 0.008, 0.007, 0.006, 0.005]:\n",
        "  for wd in [1e-4, 1e-5, 0.]:\n",
        "    model = TransformerModel(128, 2, 256, 4, 0.0).to(device)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    print(f'LR={lr}, WD={wd}')\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      model, loss, _ = train_one_epoch(model, train_loader, loss_fn, optimizer, epoch)\n",
        "    print()"
      ],
      "metadata": {
        "id": "yIta-JKgA7-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: train more epochs"
      ],
      "metadata": {
        "id": "oBW2SLfEEkCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = TransformerModel(64, 8, 64*4, 0.1, 8, 6).to(device)"
      ],
      "metadata": {
        "id": "pCCY2WecCyyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.1\n",
        "wd = 1e-4\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=wd, momentum=0.9)"
      ],
      "metadata": {
        "id": "bowjVB5yIXUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_train_hist = []\n",
        "loss_valid_hist = []\n",
        "\n",
        "acc_train_hist = []\n",
        "acc_valid_hist = []\n",
        "\n",
        "best_loss_valid = torch.inf\n",
        "epoch_counter = 0"
      ],
      "metadata": {
        "id": "FIrBCdHBIeRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  # Train\n",
        "  model, loss_train, acc_train = train_one_epoch(model,\n",
        "                                                 train_loader,\n",
        "                                                 loss_fn,\n",
        "                                                 optimizer,\n",
        "                                                 epoch)\n",
        "  # Validation\n",
        "  loss_valid, acc_valid = validation(model,\n",
        "                                     test_loader,\n",
        "                                     loss_fn)\n",
        "\n",
        "  loss_train_hist.append(loss_train)\n",
        "  loss_valid_hist.append(loss_valid)\n",
        "\n",
        "  acc_train_hist.append(acc_train)\n",
        "  acc_valid_hist.append(acc_valid)\n",
        "\n",
        "  if loss_valid < best_loss_valid:\n",
        "    torch.save(model, f'model.pt')\n",
        "    best_loss_valid = loss_valid\n",
        "\n",
        "  print(f'Valid: Loss = {loss_valid:.4}, Acc = {acc_valid:.4}')\n",
        "  print()\n",
        "\n",
        "  epoch_counter += 1"
      ],
      "metadata": {
        "id": "CAXagB4yvtZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Plot**"
      ],
      "metadata": {
        "id": "oK20iNRI3Xxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(epoch_counter), loss_train_hist, 'r-', label='Train')\n",
        "plt.plot(range(epoch_counter), loss_valid_hist, 'b-', label='Validation')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.grid(True)\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "KYFzTsdIOkVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(epoch_counter), acc_train_hist, 'r-', label='Train')\n",
        "plt.plot(range(epoch_counter), acc_valid_hist, 'b-', label='Validation')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Acc')\n",
        "plt.grid(True)\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "dUgt-mWsOqhB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}